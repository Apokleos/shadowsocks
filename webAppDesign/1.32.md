# Web应用开发实录后端篇 后端程序编写 使用 Redis 全局加速接口

在上文中，我们安装了 `redis` 服务，本节开始，我们在我们的程序中加入 `redis` 的使用，为我们的接口进行全局加速。

## 设计全局加速

实话实说，我本没有计划在这个系列的内容中加入这部分内容。但是，这不是写到这边了么，所以，这是临时加上的。所以，在构架上有点耦合了。不过这也符合我们正常的项目开发流程，就是开发着，突然就增加新需求了。也算是我们开发实战的一个应变措施吧。

首先，我们要考虑的是，我们要为哪些接口加速。因为我们做的是一个文章管理系统，而我们在管理文章的时候，并不需要加速，因为我们自己管理后台的流量并不会太大，只有我们的管理员访问而已。并且加速后，数据有缓存，那么反而影响我们的正常管理。但是在访客访问我们站点的时候，流量是非常大的，频繁的查询数据库会直接影响到系统的稳定性以及响应效率。因此，我们只需要为前台接口加速即可。

对应到我们的系统上就是只需要为 `/api/v1/fe/` 这个接口前缀的接口加速即可。同时，在前端接口中，只有查询接口的流量是最大的，而提交数据等流量较小。事实是，我们的系统的前台接口，只有查询，没有数据提交的内容。因此，我们只需要对 `ls`、 `get` 这两个请求方法加速即可。

最终我们决定这样做：

1. 所有配置信息位于 `/config.py` 文件中，便于全局管理。
2. 在数据预处理层 `/core/process.py` 和数据处理层 `/core/rest.py` 中进行加速处理。
3. 预处理层处理是否需要加速，以及加速保存键值。
4. 数据处理层根据预处理层的传参，确定是否使用加速。
5. 要考虑 `redis` 异常。

进行了这样的设计之后，我们开始撰写如下代码。

## config.py 配置参数

首先，我们来编辑 `/config.py` 文件，在中间加上我们的有关 `redis` 加速的各项配置参数，代码如下：

```python
# 数据库连接参数
REDIS_CONFIG = {
    'host': 'localhost',
    'port': 6379,
}

# 需要加速的接口前缀列表
REDIS_SPEED_API_PREFIX_LIST = ['/api/v1/fe/']

# 数据缓存时间（单位秒）
REDIS_SPEED_TIME = 5
```

为了以后考虑的扩展，我们加速接口前缀使用列表，如果有新的接口前缀需要加速，直接在这里配置上即可。此外就是数据缓存时间，这里我们统一配置。当然，如果需要单独配置的话，复杂化这个配置文件即可。

## porcess.py 数据预处理层

在预处理层中，主要是进行加速前的准备。首先，我们要判断是否需要加速。此外，最重要的是，我们在数据处理层中是不管接口请求是从哪个接口前缀来的。那里我们只管数据的处理，根据条件查询数据，返回接口。不管接口前缀。

所以，我们配置了接口加速列表，就需要在数据预处理层来进行处理了。因为这里是知道接口前缀的。而 `redis` 是一个 `key-value` 的数据库，就需要为每一个请求保存一个独立的 `key` 值，我的想法是根据接口前缀、接口名以及查询参数组织一下，成为一个独立的字符串，用于这个 `key` 值。

接口请求的参数，在我们的程序设计中是一个字典，这里，我们就需要将字典转化为字符串。所以，我们先编辑 `/core/tool.py` 文件，增加一个字典转化字符串的方法。代码如下：

```python
# 字典转字符串方法
def dict2str(dictObj):
    res = ''
    sortKeys = sorted(dictObj.keys())
    for i in sortKeys:
        res += i + '=' + str(dictObj[i]) + '-'
    return res[0:-1]
```

这里需要注意的一点是，字典是一个无序的数据类型。比如 `{'a': 1, 'b': 2}` 和 `{'b': 2, 'a': 1}` 这两个并不是同样的内容。但是，对于我们的查询结果是完全一致的。所以，我们要先进行一个排序。然后根据排序的接口进行取值并改造成字符串。

上面的 `/core/tool.py` 处理完成之后，我们就来编辑 `/core/process.py` 文件了。为了避免看官前后查看代码，这里直接上代码全文：

```python
#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

from core.tool import ok, dict2str
from core import rest
import json
# 引入配置文件中的前缀参数
from config import PREFIX, REDIS_SPEED_API_PREFIX_LIST

# 加载前后处理模块
async def doProcess(app, name, request, query, method, oid=None):
    # 是否需要缓存加速，默认否
    speed = False
    # 通过配置前缀字典，获得不同前缀字符串，并替换斜杠为下划线
    for i in PREFIX:
        if i in request.url:
            FIX = PREFIX[i]
            p = '_'.join(list(filter(None, FIX.split('/'))))
            # 查看接口是否在加速列表
            if FIX in REDIS_SPEED_API_PREFIX_LIST:
                speed = True
    
    # 组装前后处理的不同名称
    bm = p + 'before' + name
    am = p + 'after' + name

    # 进行对应前处理，非字典结果，直接抛出
    if dir(app.process.get(bm)).count(method) == 1:
        if oid == None:
            data = await getattr(app.process.get(bm), method)(query)
        else:
            data = await getattr(app.process.get(bm), method)(query, oid)

        if data:
            return data

    # 得到查询结果
    if oid == None:
        if method == 'ls':
            # 构建 redis key
            redisKeyName = p + name + dict2str(query)
            response = getattr(rest, method)(query, name, redisKeyName, speed)
        else:
            response = getattr(rest, method)(query, name)
    else:
        if method == 'get':
            # 构建 redis key
            redisKeyName = p + name + oid + dict2str(query)
            response = getattr(rest, method)(query, name, oid, redisKeyName, speed)
        else:
            response = getattr(rest, method)(query, name, oid)

    resBody = json.loads(response.body)
    resStatus = response.status
    # 根据返回结果判断是否需要后处理(错误状态就不处理了)
    if resStatus == 200 and resBody['status'] == 0 \
            and dir(app.process.get(am)).count(method) == 1:
        data = await getattr(app.process.get(am), method)(resBody['data'])
        return ok(data)
    else:
        return response
```

代码的主要逻辑在前文中已经讲过了，这里重点讲解这次追加的内容。

首先，我们定义了一个局部变量 `speed` 默认为 `False` ，如果请求的接口前缀在我们前文中配置的加速列表中，就将它改为 `True`。

其次，我们本来只是将参数组织好之后传给后面的 `rest.py` 去处理，这里我们增加了判断逻辑，首先是判断方法是否为 `ls` 或者是 `get` 这俩呢，要进行加速的一些预处理。

最后就是根据接口前缀、接口名、以及参数字典构建的字符串进行拼接，构建一个字符串，用于保存 `key` 名字。然后将这个键名以及是否需要加速，传给后面的 `rest.py` 由它去处理。

## rest.py 数据处理层

这里呢，我们主要是要进行以下工作：

1. 连接 `redis` 数据库。
2. `ls` 和 `get` 方法调整。
3. 如果 `redis` 开启，并且有加速数据，则直接取出返回。
4. 如果没有加速数据则从数据库查询数据，并存进 `redis` 加速下次接口请求速度。
5. 如果 `redis` 不存在，则直接从数据库查询。


首先，我们在 `/core/rest.py` 文件最前面撰写如下代码：

```python
# 引入配置文件
from config import REDIS_CONFIG, REDIS_SPEED_TIME
# 加载 python redis 模块
import redis
# 加载二进制序列化模块
import pickle
# 全局创建 redis 连接
r = redis.Redis(**REDIS_CONFIG)
```

这里需要解释以下，如果我们直接把查询出来的字典数据存进 `redis` ，则取出的时候，需要将这个数据进行循环遍历处理，才能在我们的程序中使用。这点计算量有点太大了。因为我们只是把 `redis` 当成一个仓库而已，我们不管其他的，也不需要在这中间进行运算。因此，我们直接序列化后存进去即可。

但是序列化有多种方式，比如我们序列化为字符串，则可以使用 `json` 模块来实现。将字典转化为字符串，然后存进 `redis` 里面。取出来的时候，再反序列化为字典即可。不过，序列化为字符串，它的运算量还是比较大的。而序列化为二进制，则计算量要小很多很多。经过我自己的测试，可以达到4倍以上的性能。因此，我这里专门引入了一个二进制序列化工具 `pickle`。

准备工作做完，我们再来调整 `ls` 方法。代码如下：

```python
def ls (request, name, key='redis', speed=False):
    hmupName = str2Hump(name)
    
    try:
        # 尝试从 redis 中获取相应数据
        redisData = r.get(key)
        # 如果得到数据，并且接口前缀启用加速则直接将查询数据返回
        if redisData and speed:
            res = pickle.loads(redisData)
            print('get by redis')
        else:
            # 否则直接从数据库中查询
            res = query.ls(hmupName, request)
            print('get by db')
            # 如果启用加速，则将查询接口存储到 redis 中
            if speed:
                r.set(key, pickle.dumps(res), ex=REDIS_SPEED_TIME)
    except:
        # 连接 redis 失败，则继续从数据库中查询
        print('redis error; get by db')
        res = query.ls(hmupName, request)

    if isinstance(res, dict):
        return ok(res)
    elif res == 400:
        return fail('参数错误', 400)
    elif res == 404:
        return fail('数据库中没有' + name + '这个表', 404, 404)
    elif res == 503:
        return fail('数据查询失败', 503)
    else:
        return fail('服务器内部错误', 500, 500)
```

好，代码写好后，我们保存代码并重启项目，测试一下是否可行！

测试命令如下：

```#
curl 'http://0.0.0.0:8000/api/v1/fe/article?pagesize=10&page=0'
```

![查询结果](https://raw.githubusercontent.com/fengcms/articles/master/image/33/01f6cb4c484113698a02813625fcc8.jpg)

查询结果如上图所示，我们的程序是完全正常运行的。我们多请求几次，看看程序端的返回是什么样子的：

![服务端结果](https://raw.githubusercontent.com/fengcms/articles/master/image/fc/e55234fedc4ecdc0cabc57febe81c2.jpg)

我们从上图可以看到，我们第一次请求数据的时候，是从数据库中查询的。而第二次请求，是从 `redis` 中直接返回的。由于我们设置的失效时间是 `5` 秒钟，所以很快我们的缓存失效了，它就会又从数据库中查询了。

然后我们尝试结束掉 `redis` 服务进程，再来看我们的程序执行结果：

![redis 服务出错](https://raw.githubusercontent.com/fengcms/articles/master/image/19/af278887ab4d937573a64b25db0ca2.jpg)

从上图中我们可以看到，我们的 `redis` 服务停止之后，并没有影响到我们的程序输出，只是打印 `redis` 出错，然后乖乖的到数据库中查询数据，并返回给客户端了。

通过这样几行简单的代码，我们就完成了接口的加速了。

下面我们照猫画虎，也同样给 `get` 方法给加上我们的 `redis` 加速：

```python
def get (request, name, oid, key='redis', speed=False):
    hmupName = str2Hump(name)

    try:
        redisData = r.get(key)
        if redisData and speed:
            res = pickle.loads(redisData)
            print('get by redis')
        else:
            res = query.get(hmupName, oid)
            print('get by db')
            if speed:
                r.set(key, pickle.dumps(res), ex=REDIS_SPEED_TIME)
    except:
        print('redis error; get by db')
        res = query.get(hmupName, oid)
            
    if isinstance(res, dict):
        return ok(res)
    elif res == 404:
        return fail('数据库中没有' + name + '这个表', 404, 404)
    elif res == 4042:
        return fail('没有这条数据', 404, 404)
    elif res == 4043:
        return fail(name + '数据库中没有数据', 404, 404)
    elif res == 503:
        return fail('数据查询失败', 503)
    else:
        return fail('服务器内部错误', 500, 500)
```

整个代码的逻辑是和上面的 `ls` 方法是一模一样的，所以这里不再赘述了。

并没有几行代码，我们就实现了我们的接口的全部加速啦！

## 相关代码调整

我们之前在 `site` 接口的前处理里面，使用了 `get` 查询方法。但是上文中，我们添加了函数参数，因此，我们需要将那边的代码也进行调整，否则就会有一些问题了。

我们编辑 `/process/api_v1_fe/before/site.py` 文件，将 `ls` 方法 调整为：

```python
async def ls(request):
    return rest.get({}, 'site', 'first', 'siteInfo', True)
```

后面的 `'siteInfo', True` 是我们新增加的参数，分别是 `Redis` 加速的键名，以及该接口启用加速。

> 本文由 FungLeo 原创，未经书面许可，严禁转载。

